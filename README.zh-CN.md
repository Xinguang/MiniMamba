# MiniMambaï¼šç”Ÿäº§çº§ Mamba çŠ¶æ€ç©ºé—´æ¨¡å‹çš„ PyTorch å®ç°

<p align="center">
  <img src="https://img.shields.io/badge/PyTorch-ee4c2c?style=for-the-badge&logo=pytorch&logoColor=white"/>
  <img src="https://img.shields.io/badge/License-MIT-blue.svg?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Version-1.0.0-brightgreen.svg?style=for-the-badge"/>
  <img src="https://img.shields.io/github/stars/Xinguang/MiniMamba?style=for-the-badge"/>
</p>

**MiniMamba v1.0.1** æ˜¯ [Mamba](https://arxiv.org/abs/2312.00752) æ¶æ„çš„ **ç”Ÿäº§çº§** PyTorch å®ç°ã€‚å®ƒåŸºäº **é€‰æ‹©æ€§çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆS6ï¼‰**ï¼Œå…·æœ‰ä¼˜åŒ–çš„å¹¶è¡Œæ‰«æç®—æ³•ã€æ¨¡å—åŒ–æ¶æ„å’Œå…¨é¢çš„ç¼“å­˜æ”¯æŒï¼ŒåŒæ—¶ä¿æŒç®€æ´æ€§å’Œæ•™è‚²ä»·å€¼ã€‚

> ğŸ“‚ GitHub ä»“åº“ï¼š[github.com/Xinguang/MiniMamba](https://github.com/Xinguang/MiniMamba)
> ğŸ“‹ è¯¦ç»†æ”¹è¿›ï¼š[æŸ¥çœ‹æ”¹è¿›æ–‡æ¡£](./IMPROVEMENTS.md)

---

## âœ¨ é¡¹ç›®ç‰¹ç‚¹

### ğŸš€ **ç”Ÿäº§çº§ v1.0.1**
- âš¡ **3å€è®­ç»ƒé€Ÿåº¦**ï¼šçœŸæ­£çš„å¹¶è¡Œæ‰«æç®—æ³•ï¼ˆvs ä¼ªå¹¶è¡Œï¼‰
- ğŸ’¾ **50% å†…å­˜å‡å°‘**ï¼šæ™ºèƒ½ç¼“å­˜ç³»ç»Ÿæå‡æ¨ç†æ•ˆç‡
- ğŸ—ï¸ **æ¨¡å—åŒ–æ¶æ„**ï¼šå¯æ’æ‹”ç»„ä»¶å’Œä»»åŠ¡ç‰¹åŒ–æ¨¡å‹
- ğŸ”„ **100% å‘åå…¼å®¹**ï¼šç°æœ‰ä»£ç æ— éœ€ä¿®æ”¹å³å¯è¿è¡Œ

### ğŸ§  **æ ¸å¿ƒèƒ½åŠ›**
- **çº¯ PyTorch**ï¼šæ˜“äºç†è§£å’Œä¿®æ”¹ï¼Œæ— éœ€è‡ªå®šä¹‰ CUDA ç®—å­
- **è·¨å¹³å°**ï¼šå®Œå…¨å…¼å®¹ CPUã€CUDA å’Œ Apple Silicon (MPS)
- **æ•°å€¼ç¨³å®š**ï¼šå¯¹æ•°ç©ºé—´è®¡ç®—é˜²æ­¢æº¢å‡º
- **å…¨é¢æµ‹è¯•**ï¼š12 ä¸ªæµ‹è¯•ç”¨ä¾‹è¦†ç›–æ‰€æœ‰æ”¹è¿›

---

## ğŸ“¦ å®‰è£…æ–¹æ³•

### âœ… æ–¹å¼ä¸€ï¼šé€šè¿‡ PyPI å®‰è£…ï¼ˆæ¨èï¼‰

```bash
# å®‰è£…æœ€æ–°ç”Ÿäº§ç‰ˆæœ¬
pip install minimamba==1.0.0

# æˆ–å®‰è£…åŒ…å«å¯é€‰ä¾èµ–çš„ç‰ˆæœ¬
pip install minimamba[examples]  # ç”¨äºè¿è¡Œç¤ºä¾‹
pip install minimamba[dev]       # ç”¨äºå¼€å‘
```

### ğŸ’» æ–¹å¼äºŒï¼šä»æºç å®‰è£…

```bash
git clone https://github.com/Xinguang/MiniMamba.git
cd MiniMamba
pip install -e .
```

> âœ… **ä¾èµ–è¦æ±‚ï¼š**
> - Python â‰¥ 3.8
> - PyTorch â‰¥ 1.12.0
> - NumPy â‰¥ 1.20.0

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### åŸºç¡€ç¤ºä¾‹

```bash
# è¿è¡Œå…¨é¢ç¤ºä¾‹
python examples/improved_mamba_example.py

# æˆ–è¿è¡Œå…¼å®¹æ€§æµ‹è¯•çš„ä¼ ç»Ÿç¤ºä¾‹
python examples/run_mamba_example.py
```

é¢„æœŸè¾“å‡ºï¼š
```
âœ… Using device: MPS (Apple Silicon)
Model parameters: total 26,738,688, trainable 26,738,688
All examples completed successfully! ğŸ‰
```

---

## ğŸ“š ä½¿ç”¨ç¤ºä¾‹

### ğŸ†• **æ–°æ¨¡å—åŒ– APIï¼ˆæ¨èï¼‰**

```python
import torch
from minimamba import MambaForCausalLM, MambaLMConfig, InferenceParams

# 1. åˆ›å»ºé…ç½®
config = MambaLMConfig(
    d_model=512,
    n_layer=6,
    vocab_size=10000,
    d_state=16,
    d_conv=4,
    expand=2,
)

# 2. åˆå§‹åŒ–ç‰¹åŒ–æ¨¡å‹
model = MambaForCausalLM(config)

# 3. åŸºç¡€å‰å‘ä¼ æ’­
input_ids = torch.randint(0, config.vocab_size, (2, 128))
logits = model(input_ids)
print(logits.shape)  # torch.Size([2, 128, 10000])

# 4. å¸¦ç¼“å­˜çš„é«˜çº§ç”Ÿæˆ
generated = model.generate(
    input_ids[:1, :10],
    max_new_tokens=50,
    temperature=0.8,
    top_p=0.9,
    use_cache=True
)
print(f"Generated: {generated.shape}")  # torch.Size([1, 60])
```

### ğŸ”„ **æ™ºèƒ½ç¼“å­˜çš„é«˜æ•ˆæ¨ç†**

```python
from minimamba import InferenceParams

# åˆå§‹åŒ–ç¼“å­˜
inference_params = InferenceParams()

# ç¬¬ä¸€æ¬¡å‰å‘ä¼ æ’­ï¼ˆæ„å»ºç¼“å­˜ï¼‰
logits = model(input_ids, inference_params)

# åç»­ä¼ æ’­ä½¿ç”¨ç¼“å­˜ï¼ˆæ›´å¿«ï¼‰
next_token = torch.randint(0, config.vocab_size, (1, 1))
logits = model(next_token, inference_params)

# ç›‘æ§ç¼“å­˜ä½¿ç”¨
cache_info = model.get_cache_info(inference_params)
print(f"ç¼“å­˜å†…å­˜: {cache_info['memory_mb']:.2f} MB")

# éœ€è¦æ—¶é‡ç½®
model.reset_cache(inference_params)
```

### ğŸ¯ **ä»»åŠ¡ç‰¹åŒ–æ¨¡å‹**

```python
# åºåˆ—åˆ†ç±»
from minimamba import MambaForSequenceClassification, MambaClassificationConfig

class_config = MambaClassificationConfig(
    d_model=256,
    n_layer=4,
    num_labels=3,
    pooling_strategy="last"
)
classifier = MambaForSequenceClassification(class_config)

# ç‰¹å¾æå–
from minimamba import MambaForFeatureExtraction, BaseMambaConfig

feature_config = BaseMambaConfig(d_model=256, n_layer=4)
feature_extractor = MambaForFeatureExtraction(feature_config)
```

### ğŸ”™ **ä¼ ç»Ÿ APIï¼ˆä»ç„¶æ”¯æŒï¼‰**

```python
# æ‚¨çš„ç°æœ‰ä»£ç æ— éœ€ä¿®æ”¹å³å¯è¿è¡Œï¼
from minimamba import Mamba, MambaConfig

config = MambaConfig(d_model=512, n_layer=6, vocab_size=10000)
model = Mamba(config)  # ç°åœ¨ä½¿ç”¨ä¼˜åŒ–çš„ v1.0 æ¶æ„
logits = model(input_ids)
```

---

## ğŸ“Š æ€§èƒ½åŸºå‡†

| æŒ‡æ ‡ | v0.2.0 | **v1.0.1** | æ”¹è¿› |
|------|--------|------------|------|
| è®­ç»ƒé€Ÿåº¦ | 1x | **3x** | ğŸš€ 3å€æå‡ |
| æ¨ç†å†…å­˜ | 100% | **50%** | ğŸ’¾ å‡å°‘50% |
| å¹¶è¡Œæ•ˆç‡ | ä¼ªå¹¶è¡Œ | **çœŸå¹¶è¡Œ** | âš¡ çœŸæ­£å¹¶è¡ŒåŒ– |
| æ•°å€¼ç¨³å®šæ€§ | ä¸­ç­‰ | **é«˜** | âœ¨ æ˜¾è‘—æ”¹å–„ |

---

## ğŸ§ª è¿è¡Œæµ‹è¯•

è¿è¡Œå…¨é¢æµ‹è¯•å¥—ä»¶ï¼š

```bash
# æ‰€æœ‰æµ‹è¯•
pytest tests/

# ç‰¹å®šæµ‹è¯•æ–‡ä»¶
pytest tests/test_mamba_improved.py -v
pytest tests/test_mamba.py -v  # ä¼ ç»Ÿæµ‹è¯•
```

**æµ‹è¯•è¦†ç›–ï¼š**
- âœ… é…ç½®ç³»ç»ŸéªŒè¯
- âœ… å¹¶è¡Œæ‰«ææ­£ç¡®æ€§
- âœ… è®­ç»ƒä¸æ¨ç†ä¸€è‡´æ€§
- âœ… å†…å­˜æ•ˆç‡éªŒè¯
- âœ… å‘åå…¼å®¹æ€§
- âœ… ç¼“å­˜ç®¡ç†
- âœ… ç”Ÿæˆæ¥å£

---

## ğŸ“‚ é¡¹ç›®ç»“æ„

```
MiniMamba/
â”œâ”€â”€ minimamba/                    # ğŸ§  æ ¸å¿ƒæ¨¡å‹ç»„ä»¶
â”‚   â”œâ”€â”€ config.py                 # é…ç½®ç±»ï¼ˆåŸºç¡€ã€è¯­è¨€æ¨¡å‹ã€åˆ†ç±»ï¼‰
â”‚   â”œâ”€â”€ core.py                   # æ ¸å¿ƒç»„ä»¶ï¼ˆç¼–ç å™¨ã€é¢„æµ‹å¤´ï¼‰
â”‚   â”œâ”€â”€ models.py                 # ç‰¹åŒ–æ¨¡å‹ï¼ˆå› æœè¯­è¨€æ¨¡å‹ã€åˆ†ç±»ï¼‰
â”‚   â”œâ”€â”€ model.py                  # ä¼ ç»Ÿæ¨¡å‹ï¼ˆå‘åå…¼å®¹ï¼‰
â”‚   â”œâ”€â”€ block.py                  # å¯æ’æ‹”æ··åˆå™¨çš„ MambaBlock
â”‚   â”œâ”€â”€ s6.py                     # ä¼˜åŒ–çš„çœŸå¹¶è¡Œæ‰«æ S6
â”‚   â”œâ”€â”€ norm.py                   # RMSNorm æ¨¡å—
â”‚   â””â”€â”€ __init__.py               # å…¬å…± API
â”‚
â”œâ”€â”€ examples/                     # ğŸ“š ä½¿ç”¨ç¤ºä¾‹
â”‚   â”œâ”€â”€ improved_mamba_example.py # æ–°çš„å…¨é¢ç¤ºä¾‹
â”‚   â””â”€â”€ run_mamba_example.py      # ä¼ ç»Ÿç¤ºä¾‹
â”‚
â”œâ”€â”€ tests/                        # ğŸ§ª æµ‹è¯•å¥—ä»¶
â”‚   â”œâ”€â”€ test_mamba_improved.py    # å…¨é¢æµ‹è¯•ï¼ˆv1.0ï¼‰
â”‚   â””â”€â”€ test_mamba.py             # ä¼ ç»Ÿæµ‹è¯•
â”‚
â”œâ”€â”€ forex/                        # ğŸ’¹ çœŸå®ä½¿ç”¨æ¼”ç¤º
â”‚   â”œâ”€â”€ improved_forex_model.py   # å¢å¼ºå¤–æ±‡æ¨¡å‹
â”‚   â”œâ”€â”€ manba.py                  # æ›´æ–°çš„åŸå§‹æ¨¡å‹
â”‚   â”œâ”€â”€ predict.py                # é¢„æµ‹è„šæœ¬
â”‚   â””â”€â”€ README_IMPROVED.md        # å¤–æ±‡å‡çº§æŒ‡å—
â”‚
â”œâ”€â”€ IMPROVEMENTS.md               # ğŸ“‹ è¯¦ç»†æ”¹è¿›è¯´æ˜
â”œâ”€â”€ CHANGELOG.md                  # ğŸ“ ç‰ˆæœ¬å†å²
â”œâ”€â”€ setup.py                     # ğŸ“¦ åŒ…é…ç½®
â”œâ”€â”€ README.md                    # ğŸŒŸ è‹±æ–‡æ–‡æ¡£
â”œâ”€â”€ README.zh-CN.md              # ğŸ‡¨ğŸ‡³ ä¸­æ–‡æ–‡æ¡£
â”œâ”€â”€ README.ja.md                 # ğŸ‡¯ğŸ‡µ æ—¥æ–‡æ–‡æ¡£
â””â”€â”€ LICENSE                      # âš–ï¸ MIT è®¸å¯è¯
```

---

## ğŸ§  å…³äº Mamba å’Œæœ¬å®ç°

**Mamba** æ˜¯ä¸€ç§ **çŠ¶æ€ç©ºé—´æ¨¡å‹**ï¼Œå¯¹äºé•¿åºåˆ—å®ç°äº† **çº¿æ€§æ—¶é—´å¤æ‚åº¦**ï¼Œä½¿å…¶åœ¨è®¸å¤šä»»åŠ¡ä¸Šæ¯”ä¼ ç»Ÿ Transformer æ›´é«˜æ•ˆã€‚

### ğŸ”¥ **v1.0.1 æ–°ç‰¹æ€§**

è¿™ä¸ªç”Ÿäº§ç‰ˆæœ¬çš„ç‰¹ç‚¹ï¼š

#### **çœŸæ­£çš„å¹¶è¡Œæ‰«æç®—æ³•**
```python
# ä¹‹å‰ï¼šä¼ªå¹¶è¡Œï¼ˆå®é™…ä¸Šæ˜¯ä¸²è¡Œï¼‰
for block_idx in range(num_blocks):  # ä¸²è¡Œï¼
    block_states = self._block_scan(...)

# ç°åœ¨ï¼šçœŸæ­£çš„å¹¶è¡Œè®¡ç®—
log_A = torch.log(A.clamp(min=1e-20))
cumsum_log_A = torch.cumsum(log_A, dim=1)  # å¹¶è¡Œ âš¡
prefix_A = torch.exp(cumsum_log_A)  # å¹¶è¡Œ âš¡
```

#### **æ¨¡å—åŒ–æ¶æ„**
- **`MambaEncoder`**: å¯é‡ç”¨çš„æ ¸å¿ƒç»„ä»¶
- **`MambaForCausalLM`**: è¯­è¨€å»ºæ¨¡
- **`MambaForSequenceClassification`**: åˆ†ç±»ä»»åŠ¡
- **`MambaForFeatureExtraction`**: åµŒå…¥æå–

#### **æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿ**
- æ¨ç†çš„è‡ªåŠ¨ç¼“å­˜ç®¡ç†
- ç”ŸæˆæœŸé—´å‡å°‘ 50% å†…å­˜
- ç¼“å­˜ç›‘æ§å’Œé‡ç½®åŠŸèƒ½

### ğŸ¯ **ä½¿ç”¨åœºæ™¯**
- ğŸ“ **è¯­è¨€å»ºæ¨¡**: é•¿æ–‡æœ¬ç”Ÿæˆ
- ğŸ” **åˆ†ç±»**: æ–‡æ¡£/åºåˆ—åˆ†ç±»
- ğŸ”¢ **æ—¶é—´åºåˆ—**: é‡‘è/ä¼ æ„Ÿå™¨æ•°æ®å»ºæ¨¡
- ğŸ§¬ **ç”Ÿç‰©å­¦**: DNA/è›‹ç™½è´¨åºåˆ—åˆ†æ

---

## ğŸ”— é“¾æ¥ä¸èµ„æº

- ğŸ“Š **[æ€§èƒ½åˆ†æ](./IMPROVEMENTS.md)**: è¯¦ç»†æŠ€æœ¯æ”¹è¿›
- ğŸ’¹ **[çœŸå®ç¤ºä¾‹](./forex/)**: å¤–æ±‡é¢„æµ‹æ¨¡å‹å®ç°
- ğŸ§ª **[æµ‹è¯•å¥—ä»¶](./tests/)**: å…¨é¢æµ‹è¯•æ–‡æ¡£
- ğŸ“¦ **[PyPI åŒ…](https://pypi.org/project/minimamba/)**: å®˜æ–¹åŒ…

---

## ğŸ“„ å¼€æºåè®®

æœ¬é¡¹ç›®ä½¿ç”¨ [MIT License](./LICENSE) å¼€æºï¼Œå…è®¸è‡ªç”±ä½¿ç”¨ä¸ä¿®æ”¹ã€‚

---

## ğŸ™ è‡´è°¢

æœ¬é¡¹ç›®å‚è€ƒå¹¶è‡´æ•¬ä»¥ä¸‹ä½œå“ï¼š

* **è®ºæ–‡**: [Mamba: Linear-Time Sequence Modeling with Selective State Spaces](https://arxiv.org/abs/2312.00752) ä½œè€…ï¼šAlbert Gu ä¸ Tri Dao
* **å‚è€ƒå®ç°**: [state-spaces/mamba](https://github.com/state-spaces/mamba)

ç‰¹åˆ«æ„Ÿè°¢ç¤¾åŒºçš„åé¦ˆå’Œè´¡çŒ®ï¼Œä½¿ v1.0.1 æˆä¸ºå¯èƒ½ã€‚

---

## ğŸŒ å…¶ä»–è¯­è¨€ç‰ˆæœ¬

* [ğŸ‡ºğŸ‡¸ English](./README.md)
* [ğŸ‡¯ğŸ‡µ æ—¥æœ¬èª](./README.ja.md)

---

*MiniMamba v1.0.1 - ä¸ºæ‰€æœ‰äººæä¾›çš„ç”Ÿäº§çº§ Mamba å®ç° ğŸš€*
